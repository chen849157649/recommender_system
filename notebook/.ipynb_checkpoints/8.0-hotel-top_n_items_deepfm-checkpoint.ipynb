{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM Recommender System - Expedia Hotel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yas/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import math\n",
    "from math import sqrt\n",
    "import sys\n",
    "import holidays\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr.inputs import build_input_features, get_linear_logit, input_from_feature_columns, combined_dnn_input\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.utils import add_func\n",
    "from deepctr.models import WDL, DeepFM\n",
    "from deepctr.inputs import SparseFeat,get_feature_names\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500000, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/hotel_data/train.csv', sep=',', nrows=1500000)\n",
    "destinations = pd.read_csv('../data/hotel_data/destinations.csv', sep=',')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge only top 10 most correlated columns with rating column\n",
    "df = pd.merge(df,destinations[['srch_destination_id','d33', 'd64', 'd52', 'd120', 'd72', 'd136', 'd7', 'd59', 'd50', 'd30']],on='srch_destination_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename 2 columns\n",
    "df = df.rename(columns={'hotel_cluster': 'item_id', 'is_booking': 'rating'})\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "from pandas.tseries.offsets import Week\n",
    "df = df.sort_values(\"date_time\").reset_index()\n",
    "df.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date_time\"] =  pd.to_datetime(df[\"date_time\"], infer_datetime_format=True)\n",
    "df[\"date_time\"] = df.date_time.dt.strftime('%Y-%m-%d')\n",
    "#df[\"date_time_timestamp\"] =  pd.to_datetime(df[\"date_time\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.timedelta(days=14)\n",
    "df['lagged_date_time'] = df[\"date_time\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\") + d)\n",
    "\n",
    "def extract_week(feature,week,lag):\n",
    "    df[feature] =  pd.to_datetime(df[feature], infer_datetime_format=True)\n",
    "    df[feature] = df.date_time.dt.strftime('%Y-%m-%d')\n",
    "    if lag == True:\n",
    "        d = datetime.timedelta(days=14)\n",
    "        df['lag_date_time'] = df[feature].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\") + d)\n",
    "        df['week'] = pd.DatetimeIndex(df['lag_date_time']).week\n",
    "        df['year']=pd.DatetimeIndex(df['lag_date_time']).year\n",
    "        \n",
    "        # countinue week numbers for the next year\n",
    "        df[week] = df['week'].where(df['year'] ==2013 , df['week']+52)\n",
    "extract_week('date_time','click_week',lag=True)\n",
    "\n",
    "# extract month from date_time\n",
    "df['click_month'] = pd.DatetimeIndex(df['date_time']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['checkin_month'] = pd.DatetimeIndex(df['srch_ci']).month\n",
    "df['checkout_month'] = pd.DatetimeIndex(df['srch_co']).month\n",
    "\n",
    "df['checkin_year'] = pd.DatetimeIndex(df['srch_ci']).year\n",
    "df['checkout_year'] = pd.DatetimeIndex(df['srch_co']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define holidays in some countries\n",
    "ca_holidays = holidays.Canada()\n",
    "us_holidays = holidays.UnitedStates()\n",
    "\n",
    "# check if checkin or checkout date is in holiday of different countries\n",
    "\n",
    "df['north_am_ci'] = df['srch_ci'].apply(lambda x: 1 if x in (us_holidays or ca_holidays)  else 0)\n",
    "df['north_am_co'] = df['srch_co'].apply(lambda x: 1 if x in (us_holidays or ca_holidays)  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(['date_time'],axis=1)\n",
    "df= df.drop(['week'],axis=1)\n",
    "df= df.drop(['year'],axis=1)\n",
    "df= df.drop(['srch_ci'],axis=1)\n",
    "df= df.drop(['srch_co'],axis=1)\n",
    "df= df.drop(['lag_date_time'],axis=1)\n",
    "#df= df.drop(['date_time_timestamp'],axis=1)\n",
    "df= df.drop(['lagged_date_time'],axis=1)\n",
    "#df= df.drop(['num_visit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that we add 1 to the raw count to prevent the logarithm from\n",
    "# exploding into negative infinity in case the count is zero.\n",
    "df['log_orig_destination_distance'] = np.log10(df['orig_destination_distance'] + 1)\n",
    "\n",
    "df= df.drop(['orig_destination_distance'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def create_cluster(feature):\n",
    "    y = df[feature]\n",
    "    X = df.drop(feature,axis=1)\n",
    "    wcss=[]\n",
    "    for i in range(1,11):\n",
    "        kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n",
    "        kmeans.fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    plt.plot(range(1,11), wcss)\n",
    "    plt.title('The Elbow Method')\n",
    "    plt.xlabel('number of clusters')\n",
    "    plt.ylabel('wcss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"user_location_region\",axis=1)\n",
    "kmeansmodel = KMeans(n_clusters= 3, init='k-means++', random_state=0)\n",
    "y_kmeans= kmeansmodel.fit_predict(X)\n",
    "df['kmeans_user_location_region']=y_kmeans\n",
    "df= df.drop(['user_location_region'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"user_location_city\",axis=1)\n",
    "kmeansmodel = KMeans(n_clusters= 3, init='k-means++', random_state=0)\n",
    "y_kmeans= kmeansmodel.fit_predict(X)\n",
    "df['kmeans_user_location_city']=y_kmeans\n",
    "df= df.drop(['user_location_city'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "condlist = [(df['srch_adults_cnt']==0) & (df['srch_children_cnt']==0),\n",
    "            (df['srch_adults_cnt']==2) & (df['srch_children_cnt']==0),\n",
    "            (df['srch_adults_cnt']==2) & (df['srch_children_cnt']==1),\n",
    "            (df['srch_adults_cnt']==2) & (df['srch_children_cnt']==2),\n",
    "           (df['srch_adults_cnt']==1) & (df['srch_children_cnt']==0),\n",
    "            (df['srch_adults_cnt']>1) & (df['srch_children_cnt']>0),\n",
    "           (df['srch_adults_cnt']==1) & (df['srch_children_cnt'] > 0),\n",
    "           (df['srch_adults_cnt']>2) & (df['srch_children_cnt'] == 0),\n",
    "           (df['srch_adults_cnt']==0) & (df['srch_children_cnt'] > 0)]\n",
    "\n",
    "choicelist = ['empty_room',\n",
    "                'couple_with_no_children',\n",
    "                'couple_with_one_child',\n",
    "                'couple_with_two_children',\n",
    "                'single',\n",
    "                'big_family',\n",
    "                'single_parent',\n",
    "                'friends',\n",
    "                'unsupervised_children']\n",
    "\n",
    "df['family_status'] = np.select(condlist,choicelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the family_status into dummy variables\n",
    "dummies = pd.get_dummies(df['family_status'],drop_first=True)\n",
    "df= pd.concat( [df.drop('family_status',axis=1),dummies],axis=1)\n",
    "\n",
    "if \"unsupervised_children\" in df.columns:\n",
    "    df= df.drop(\"unsupervised_children\",axis=1)\n",
    "if \"empty_room\" in df.columns:\n",
    "    df= df.drop(\"empty_room\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cnt'] = (df['cnt'] - df['cnt'].mean())/df['cnt'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categ_sparse / conti_dense\n",
    "sparse_features = [\"site_name\", #ID of the Expedia point of sale (i.e. Expedia.com, Expedia.co.uk, Expedia.co.jp, …)\n",
    "\"posa_continent\", #ID of continent associated with site_name\n",
    "\"user_location_country\", #The ID of the country the customer is located\n",
    "\"kmeans_user_location_region\", #The ID of the region the customer is located clustered in 2 groups\n",
    "\"kmeans_user_location_city\", #The ID of the city the customer is located clustered in 2 groups\n",
    "\"user_id\", #ID of user\n",
    "\"is_mobile\", #1 when a user connected from a mobile device, 0 otherwise\n",
    "\"is_package\", #1 if the click/booking was generated as a part of a package (i.e. combined with a flight), 0 otherwise\n",
    "\"channel\", #ID of a marketing channel\n",
    "\"cnt\", #Numer of similar events in the context of the same user session\n",
    "\"srch_destination_id\", #ID of the destination where the hotel search was performed'\n",
    "\"srch_destination_type_id\", #Type of destination\n",
    "\"hotel_continent\", #'Hotel continent',\n",
    "\"hotel_country\", #Hotel country\n",
    "\"item_id\", #(hotel_cluster)ID of a hotel cluster\n",
    "\"north_am_ci\", # 1 if check-in date it's a holiday in north America\n",
    "\"north_am_co\",# 1 if check-out date it's a holiday in north America\n",
    "'hotel_market', #Hotel market\n",
    "'couple_with_no_children','couple_with_one_child','couple_with_two_children',\"friends\",\"single\",\"single_parent\",\n",
    "#hotel search latent attributes highly correlated with rating:\n",
    "'d33', 'd64','d52','d120', 'd72', 'd136', 'd7', 'd59', 'd50', 'd30'] \n",
    "\n",
    "dense_features = [\"srch_adults_cnt\", #The number of adults specified in the hotel room\n",
    "\"srch_children_cnt\", #The number of (extra occupancy) children specified in the hotel room\n",
    "\"srch_rm_cnt\", #The number of hotel rooms specified in the search\n",
    "'log_orig_destination_distance', # Log transformed physical distance between a hotel and a customer at the time of search\n",
    "\"click_week\",\n",
    "\"click_month\",\n",
    "\"checkin_month\",\n",
    "\"checkout_month\",\n",
    "\"checkin_year\",\n",
    "\"checkout_year\"]\n",
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for sparse features,and normalization for dense numerical features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    df[feat] = lbe.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "df[dense_features] = mms.fit_transform(df[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feature columns\n",
    "For sparse features, we transform them into dense vectors by embedding techniques. For dense numerical features, we concatenate them to the input tensors of fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count #unique features for each sparse field\n",
    "fixlen_feature_columns = [SparseFeat(feat, df[feat].nunique(),embedding_dim=4)\n",
    "                          for feat in sparse_features]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the training samples and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate input data for model\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "train_model_input = {name:train[name].values for name in feature_names}\n",
    "test_model_input = {name:test[name].values for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((658258, 45), (282111, 45))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best DeepFM Model after hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yas/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/yas/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/yas/opt/anaconda3/lib/python3.7/site-packages/deepctr/layers/utils.py:163: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(128,128)\n",
    "            , init_std=0.0001, seed=1024, dnn_dropout=0.5, dnn_activation='relu',task='binary',\n",
    "               fm_group=['default_group'],dnn_use_bn=False)\n",
    "\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 526606 samples, validate on 131652 samples\n",
      "Epoch 1/10\n",
      "526606/526606 - 37s - loss: 0.0758 - mean_squared_error: 0.0740 - val_loss: 0.0734 - val_mean_squared_error: 0.0709\n",
      "Epoch 2/10\n",
      "526606/526606 - 30s - loss: 0.0730 - mean_squared_error: 0.0701 - val_loss: 0.0740 - val_mean_squared_error: 0.0712\n",
      "Epoch 3/10\n",
      "526606/526606 - 28s - loss: 0.0722 - mean_squared_error: 0.0691 - val_loss: 0.0745 - val_mean_squared_error: 0.0714\n",
      "Epoch 4/10\n",
      "526606/526606 - 28s - loss: 0.0716 - mean_squared_error: 0.0685 - val_loss: 0.0747 - val_mean_squared_error: 0.0716\n",
      "Epoch 5/10\n",
      "526606/526606 - 30s - loss: 0.0710 - mean_squared_error: 0.0679 - val_loss: 0.0746 - val_mean_squared_error: 0.0716\n",
      "Epoch 6/10\n",
      "526606/526606 - 29s - loss: 0.0705 - mean_squared_error: 0.0673 - val_loss: 0.0752 - val_mean_squared_error: 0.0721\n",
      "Epoch 7/10\n",
      "526606/526606 - 30s - loss: 0.0703 - mean_squared_error: 0.0670 - val_loss: 0.0760 - val_mean_squared_error: 0.0727\n",
      "Epoch 8/10\n",
      "526606/526606 - 33s - loss: 0.0702 - mean_squared_error: 0.0666 - val_loss: 0.0765 - val_mean_squared_error: 0.0732\n",
      "Epoch 9/10\n",
      "526606/526606 - 31s - loss: 0.0700 - mean_squared_error: 0.0664 - val_loss: 0.0763 - val_mean_squared_error: 0.0727\n",
      "Epoch 10/10\n",
      "526606/526606 - 28s - loss: 0.0699 - mean_squared_error: 0.0661 - val_loss: 0.0768 - val_mean_squared_error: 0.0731\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(test_model_input, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:\t0.271000\n",
      "MAE:\t0.140000\n",
      "MSE:\t0.073000\n",
      "AUC:\t0.781000\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(test[target].values, pred_ans)\n",
    "print(\"RMSE:\\t%f\" % np.round(math.sqrt(mean_squared_error(test[target].values, pred_ans)),3),\n",
    "      \"MAE:\\t%f\" % np.round(mean_absolute_error(test[target].values, pred_ans),3),\n",
    "      \"MSE:\\t%f\" % np.round(mean_squared_error(test[target].values, pred_ans),3),\n",
    "      \"AUC:\\t%f\" % np.round(auc,3),\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "new_df = test[['rating','item_id','user_id']]\n",
    "\n",
    "#replace the rating with algorithm generated output\n",
    "new_df['rating']=pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479619</th>\n",
       "      <td>0.001050</td>\n",
       "      <td>97</td>\n",
       "      <td>17859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147990</th>\n",
       "      <td>0.024518</td>\n",
       "      <td>91</td>\n",
       "      <td>21103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769502</th>\n",
       "      <td>0.000319</td>\n",
       "      <td>59</td>\n",
       "      <td>27928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91391</th>\n",
       "      <td>0.153385</td>\n",
       "      <td>48</td>\n",
       "      <td>4788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38904</th>\n",
       "      <td>0.096915</td>\n",
       "      <td>69</td>\n",
       "      <td>18090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25656</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>98</td>\n",
       "      <td>6099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478452</th>\n",
       "      <td>0.112156</td>\n",
       "      <td>4</td>\n",
       "      <td>2472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188862</th>\n",
       "      <td>0.152395</td>\n",
       "      <td>41</td>\n",
       "      <td>1606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514057</th>\n",
       "      <td>0.041339</td>\n",
       "      <td>69</td>\n",
       "      <td>31645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256190</th>\n",
       "      <td>0.314642</td>\n",
       "      <td>7</td>\n",
       "      <td>34020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282111 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rating  item_id  user_id\n",
       "479619  0.001050       97    17859\n",
       "147990  0.024518       91    21103\n",
       "769502  0.000319       59    27928\n",
       "91391   0.153385       48     4788\n",
       "38904   0.096915       69    18090\n",
       "...          ...      ...      ...\n",
       "25656   0.000182       98     6099\n",
       "478452  0.112156        4     2472\n",
       "188862  0.152395       41     1606\n",
       "514057  0.041339       69    31645\n",
       "256190  0.314642        7    34020\n",
       "\n",
       "[282111 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4db6771ff4401aa1e2c8f86ce12c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#csr_matrix((data, (row, col))\n",
    "sparse_item_user = sparse.csr_matrix((new_df['rating'].astype(float),(new_df['item_id'], new_df['user_id'])))\n",
    "sparse_user_item = sparse.csr_matrix((new_df['rating'].astype(float),(new_df['user_id'], new_df['item_id'])))\n",
    "\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20,regularization=0.1,iterations=20)\n",
    "alpha_val = 15\n",
    "data_conf = (sparse_item_user * alpha_val).astype('double')\n",
    "model.fit(data_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_clusters(item_id,n_similar):\n",
    "    similar = model.similar_items(item_id,n_similar)\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 65 is in hotel_resort and the results have 4 out of 5 clusters in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65, 0.823982),\n",
       " (52, 0.8199171),\n",
       " (87, 0.8089151),\n",
       " (66, 0.8022266),\n",
       " (31, 0.77161545),\n",
       " (96, 0.70043224)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_clusters(65,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70 is in business_hotels and the results have 2 out of 5 clusters in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(70, 0.85447913),\n",
       " (56, 0.76396084),\n",
       " (98, 0.62938166),\n",
       " (69, 0.594637),\n",
       " (41, 0.54545015),\n",
       " (97, 0.4288375)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_clusters(70,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 is in private_vacation_homes and the results have 2 out of 5 clusters in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.9359653),\n",
       " (49, 0.47150153),\n",
       " (21, 0.42341626),\n",
       " (17, 0.41468728),\n",
       " (50, 0.39217094),\n",
       " (33, 0.38477224)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_clusters(4,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare that if the results are similar with the defined following clusters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe to store clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_df = pd.DataFrame(columns=['item_id','hotel_type'])\n",
    "hotel_df['item_id']=list(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = {\"apartment\":[5, 11, 22, 28,41, 56, 73],\n",
    "          'business_hotels':[ 64,69, 70, 97],\n",
    "          \"condo\":[3,8,36, 37, 55],\n",
    "          \"private_vacation_homes\":[ 4, 9, 21, 49, 75, 77],\n",
    "          \"motel\":[2,25,27, 95, 98],\n",
    "          \"beach_resort\":[0, 17, 26, 31, 34, 80, 84, 92],\n",
    "          \"casino_hotel\":[1, 19, 45, 54, 79,89, 93],\n",
    "          \"hotel_resort\":[52, 65, 66, 87, 96],\n",
    "          \"bed_n_breakfast\":[23, 39, 50, 51, 76],\n",
    "          \"hosetel\":[12, 20, 38, 53, 57, 60, 61, 85, 86]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for i in cluster.keys():\n",
    "    hotel_df['hotel_type'][cluster[i]]= i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>hotel_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>beach_resort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>casino_hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>motel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>condo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>private_vacation_homes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>motel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>hotel_resort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>business_hotels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>motel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id              hotel_type\n",
       "0         0            beach_resort\n",
       "1         1            casino_hotel\n",
       "2         2                   motel\n",
       "3         3                   condo\n",
       "4         4  private_vacation_homes\n",
       "..      ...                     ...\n",
       "95       95                   motel\n",
       "96       96            hotel_resort\n",
       "97       97         business_hotels\n",
       "98       98                   motel\n",
       "99       99                     NaN\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method 2 for finding similar clusters (Method 1 is more accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_matrix = new_df.pivot_table(index='user_id',columns='item_id',values='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>number_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040107</td>\n",
       "      <td>3426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083191</td>\n",
       "      <td>3782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.113924</td>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054603</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.106419</td>\n",
       "      <td>2958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rating  number_ratings\n",
       "item_id                          \n",
       "0        0.040107            3426\n",
       "1        0.083191            3782\n",
       "2        0.113924            2891\n",
       "3        0.054603            1463\n",
       "4        0.106419            2958"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.DataFrame(new_df.groupby('item_id')['rating'].mean())\n",
    "ratings['number_ratings'] = pd.DataFrame(new_df.groupby('item_id')['rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_clusters(cluster_number):\n",
    "    #Select user ratings for twohotel_matrixmovies \n",
    "    item_user_ratings = hotel_matrix[cluster_number]\n",
    "\n",
    "    # Find correlations between series with corrwith (instead of corr)\n",
    "    similar_to_hotel = hotel_matrix.corrwith(item_user_ratings)\n",
    "\n",
    "    # Removing NaN values and using a DataFrame instead of a series \n",
    "    corr_hotel = pd.DataFrame(similar_to_hotel,columns=['Correlation'])\n",
    "    corr_hotel.dropna(inplace=True)\n",
    "\n",
    "    corr_hotel = corr_hotel.join(ratings['number_ratings'])\n",
    "\n",
    "    result = corr_hotel[corr_hotel['number_ratings']>0].sort_values('Correlation',ascending=False).head()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correlation</th>\n",
       "      <th>number_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.729484</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.676894</td>\n",
       "      <td>2497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.675652</td>\n",
       "      <td>3426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.630496</td>\n",
       "      <td>3193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Correlation  number_ratings\n",
       "item_id                             \n",
       "65          1.000000            5892\n",
       "27          0.729484             541\n",
       "66          0.676894            2497\n",
       "0           0.675652            3426\n",
       "40          0.630496            3193"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "find_similar_clusters(65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
